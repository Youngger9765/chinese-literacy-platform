# AI è©•åˆ†å¼•æ“è¨­è¨ˆ

> **ç›®æ¨™**: è‡ªå‹•è©•åˆ†æœ—è®€ä½œæ¥­ (STT + ç™¼éŸ³åˆ†æ + æµæš¢åº¦)
>
> **æŠ€è¡“**: Whisper (STT) + è‡ªè¨‚ç™¼éŸ³è©•åˆ†æ¼”ç®—æ³•

---

## ğŸ¯ è©•åˆ†ç¶­åº¦

### æœ—è®€ä½œæ¥­è©•åˆ†æ¨™æº–

| ç¶­åº¦ | æ¬Šé‡ | è©•åˆ†æ–¹å¼ | ç¯„åœ |
|------|------|---------|------|
| **ç™¼éŸ³æº–ç¢ºåº¦** | 40% | éŸ³ç´ æ¯”å° (Phoneme Alignment) | 0-100 |
| **æµæš¢åº¦** | 30% | åœé “æ¬¡æ•¸ + èªé€Ÿ | 0-100 |
| **æº–ç¢ºæ€§** | 30% | éŒ¯èª¤å­—æ•¸ / ç¸½å­—æ•¸ | 0-100 |

**æœ€çµ‚åˆ†æ•¸** = ç™¼éŸ³ Ã— 0.4 + æµæš¢åº¦ Ã— 0.3 + æº–ç¢ºæ€§ Ã— 0.3

---

## ğŸ“ æ¶æ§‹è¨­è¨ˆ

```
å­¸ç”Ÿä¸Šå‚³éŸ³æª” (MP3/WAV)
    â†“
S3 å„²å­˜
    â†“
AI è©•åˆ†å¼•æ“
    â†“
æ­¥é©Ÿ 1: STT (Whisper) â†’ è¾¨è­˜æ–‡å­—
    â†“
æ­¥é©Ÿ 2: æ–‡å­—æ¯”å° â†’ è¨ˆç®—æº–ç¢ºæ€§
    â†“
æ­¥é©Ÿ 3: éŸ³ç´ åˆ†æ â†’ è¨ˆç®—ç™¼éŸ³æº–ç¢ºåº¦
    â†“
æ­¥é©Ÿ 4: éŸ»å¾‹åˆ†æ â†’ è¨ˆç®—æµæš¢åº¦
    â†“
æ­¥é©Ÿ 5: ç¶œåˆè©•åˆ† â†’ å„²å­˜åˆ°è³‡æ–™åº«
    â†“
æ•™å¸«å¾Œå°æª¢è¦– + æ‰‹å‹•èª¿æ•´
```

---

## 1ï¸âƒ£ STT (Speech-to-Text)

### 1.1 æŠ€è¡“é¸å‹

| æ–¹æ¡ˆ | å„ªå‹¢ | åŠ£å‹¢ | æˆæœ¬ |
|------|------|------|------|
| **OpenAI Whisper** | âœ… é–‹æºå…è²»<br>âœ… ä¸­æ–‡æº–ç¢ºç‡é«˜ (>95%)<br>âœ… æœ¬åœ°éƒ¨ç½² | âš ï¸ GPU éœ€æ±‚ | $0 (è‡ªå»º) |
| **Google Speech-to-Text** | âœ… API æ–¹ä¾¿ | âŒ ä»˜è²» ($0.006/15ç§’) | $360/æœˆ |
| **Azure Speech** | âœ… ç™¼éŸ³è©•åˆ† API | âŒ ä»˜è²» ($1/1000 æ¬¡) | $150/æœˆ |

**é¸æ“‡**: **Whisper (self-hosted)** - å…è²» + æº–ç¢ºç‡é«˜

---

### 1.2 Whisper å¯¦ä½œ

```typescript
// src/services/WhisperService.ts
import { Injectable, Logger } from '@nestjs/common';
import { exec } from 'child_process';
import { promisify } from 'util';
import * as fs from 'fs';

const execAsync = promisify(exec);

@Injectable()
export class WhisperService {
  private readonly logger = new Logger(WhisperService.name);
  private readonly modelPath = '/models/whisper-medium'; // ä½¿ç”¨ medium æ¨¡å‹ (å¹³è¡¡æº–ç¢ºç‡èˆ‡é€Ÿåº¦)

  /**
   * STT: éŸ³æª” â†’ æ–‡å­— + Timestamps
   */
  async transcribe(audioFilePath: string): Promise<WhisperOutput> {
    this.logger.log(`Transcribing audio: ${audioFilePath}`);

    // å‘¼å« Whisper CLI (æˆ–ä½¿ç”¨ Python API)
    const { stdout } = await execAsync(
      `whisper ${audioFilePath} --model medium --language zh --output_format json --output_dir /tmp`
    );

    // è®€å–è¼¸å‡ºçš„ JSON
    const jsonPath = audioFilePath.replace(/\.(mp3|wav)$/, '.json');
    const result = JSON.parse(fs.readFileSync(jsonPath, 'utf-8'));

    return {
      text: result.text, // å®Œæ•´è¾¨è­˜æ–‡å­—
      segments: result.segments.map((seg: any) => ({
        start: seg.start, // é–‹å§‹æ™‚é–“ (ç§’)
        end: seg.end, // çµæŸæ™‚é–“
        text: seg.text, // ç‰‡æ®µæ–‡å­—
      })),
    };
  }

  /**
   * å¸¶è©å½™æç¤ºçš„ STT (æé«˜ç”Ÿå­—è¾¨è­˜ç‡)
   */
  async transcribeWithPrompt(audioFilePath: string, vocabulary: string[]): Promise<WhisperOutput> {
    // Whisper æ”¯æ´ initial_prompt (æä¾›ä¸Šä¸‹æ–‡)
    const prompt = `é€™æ˜¯åœ‹èªæœ—è®€ä½œæ¥­,åŒ…å«ä»¥ä¸‹ç”Ÿå­—:${vocabulary.join('ã€')}`;

    const { stdout } = await execAsync(
      `whisper ${audioFilePath} --model medium --language zh --initial_prompt "${prompt}" --output_format json --output_dir /tmp`
    );

    // ... (åŒä¸Š)
  }
}
```

---

## 2ï¸âƒ£ æ–‡å­—æ¯”å° (æº–ç¢ºæ€§è©•åˆ†)

### 2.1 æ¼”ç®—æ³•: Levenshtein Distance

```typescript
// src/services/TextComparisonService.ts
import { Injectable } from '@nestjs/common';

@Injectable()
export class TextComparisonService {
  /**
   * è¨ˆç®—æº–ç¢ºæ€§åˆ†æ•¸ (0-100)
   */
  calculateAccuracy(expected: string, recognized: string): AccuracyResult {
    // 1. æ­£è¦åŒ–æ–‡å­— (ç§»é™¤æ¨™é»ç¬¦è™Ÿã€ç©ºæ ¼)
    const normalizedExpected = this.normalize(expected);
    const normalizedRecognized = this.normalize(recognized);

    // 2. è¨ˆç®—ç·¨è¼¯è·é›¢ (Levenshtein Distance)
    const distance = this.levenshteinDistance(normalizedExpected, normalizedRecognized);

    // 3. è¨ˆç®—æº–ç¢ºç‡
    const maxLength = Math.max(normalizedExpected.length, normalizedRecognized.length);
    const accuracy = ((maxLength - distance) / maxLength) * 100;

    // 4. æ‰¾å‡ºéŒ¯èª¤çš„å­—
    const errors = this.findErrors(normalizedExpected, normalizedRecognized);

    return {
      accuracy: Math.max(0, accuracy), // ç¢ºä¿ >= 0
      expectedLength: normalizedExpected.length,
      recognizedLength: normalizedRecognized.length,
      errors, // éŒ¯èª¤å­—åˆ—è¡¨
    };
  }

  /**
   * æ­£è¦åŒ–æ–‡å­— (ç§»é™¤æ¨™é»ã€ç©ºæ ¼ã€è½‰ç°¡é«”ç­‰)
   */
  private normalize(text: string): string {
    return text
      .replace(/[,ã€‚!?ã€;:ã€Œã€ã€ã€\s]/g, '') // ç§»é™¤æ¨™é»ç¬¦è™Ÿ
      .toLowerCase();
  }

  /**
   * Levenshtein Distance (ç·¨è¼¯è·é›¢)
   */
  private levenshteinDistance(a: string, b: string): number {
    const matrix: number[][] = [];

    for (let i = 0; i <= b.length; i++) {
      matrix[i] = [i];
    }

    for (let j = 0; j <= a.length; j++) {
      matrix[0][j] = j;
    }

    for (let i = 1; i <= b.length; i++) {
      for (let j = 1; j <= a.length; j++) {
        if (b[i - 1] === a[j - 1]) {
          matrix[i][j] = matrix[i - 1][j - 1];
        } else {
          matrix[i][j] = Math.min(
            matrix[i - 1][j - 1] + 1, // æ›¿æ›
            matrix[i][j - 1] + 1, // æ’å…¥
            matrix[i - 1][j] + 1 // åˆªé™¤
          );
        }
      }
    }

    return matrix[b.length][a.length];
  }

  /**
   * æ‰¾å‡ºéŒ¯èª¤çš„å­— (ç”¨ Dynamic Programming Alignment)
   */
  private findErrors(expected: string, recognized: string): ErrorDetail[] {
    const errors: ErrorDetail[] = [];

    // ä½¿ç”¨ DP è¿½æº¯è·¯å¾‘æ‰¾å‡ºéŒ¯èª¤ä½ç½®
    // (ç°¡åŒ–ç‰ˆ,å¯¦éš›éœ€è¦æ›´è¤‡é›œçš„å°é½Šæ¼”ç®—æ³•)
    for (let i = 0; i < Math.max(expected.length, recognized.length); i++) {
      if (expected[i] !== recognized[i]) {
        errors.push({
          position: i,
          expected: expected[i] || '(ç¼ºå°‘)',
          recognized: recognized[i] || '(å¤šé¤˜)',
        });
      }
    }

    return errors;
  }
}
```

---

## 3ï¸âƒ£ ç™¼éŸ³æº–ç¢ºåº¦è©•åˆ†

### 3.1 æ–¹æ³•: éŸ³ç´ æ™‚é–“å°é½Š (Phoneme Alignment)

```typescript
// src/services/PronunciationService.ts
import { Injectable } from '@nestjs/common';

@Injectable()
export class PronunciationService {
  /**
   * è¨ˆç®—ç™¼éŸ³æº–ç¢ºåº¦ (0-100)
   */
  async calculatePronunciationScore(
    audioFilePath: string,
    expectedText: string,
    recognizedSegments: WhisperSegment[]
  ): Promise<number> {
    // 1. å–å¾—é æœŸçš„éŸ³ç´ åºåˆ— (Phoneme Sequence)
    const expectedPhonemes = await this.textToPhonemes(expectedText);

    // 2. åˆ†æéŸ³æª”çš„å¯¦éš›éŸ³ç´  (ä½¿ç”¨ Forced Alignment)
    const actualPhonemes = await this.audioToPhonemes(audioFilePath, recognizedSegments);

    // 3. è¨ˆç®—éŸ³ç´ ç›¸ä¼¼åº¦
    const similarity = this.comparePhonemes(expectedPhonemes, actualPhonemes);

    return similarity * 100;
  }

  /**
   * æ–‡å­— â†’ éŸ³ç´ åºåˆ— (ä¸­æ–‡æ³¨éŸ³)
   */
  private async textToPhonemes(text: string): Promise<Phoneme[]> {
    // ä½¿ç”¨ä¸­æ–‡æ³¨éŸ³å­—å…¸ (æˆ– API)
    // ä¾‹: å®¶ â†’ ã„ã„§ã„š â†’ ['j', 'i', 'a']
    const phonemes: Phoneme[] = [];

    for (const char of text) {
      const pinyin = await this.getPinyin(char); // æŸ¥å­—å…¸
      phonemes.push(...this.pinyinToPhonemes(pinyin));
    }

    return phonemes;
  }

  /**
   * éŸ³æª” â†’ éŸ³ç´ åºåˆ— (Forced Alignment)
   */
  private async audioToPhonemes(
    audioFilePath: string,
    segments: WhisperSegment[]
  ): Promise<Phoneme[]> {
    // ä½¿ç”¨ Montreal Forced Aligner (MFA) æˆ–é¡ä¼¼å·¥å…·
    // è¼¸å…¥: éŸ³æª” + æ–‡å­—
    // è¼¸å‡º: éŸ³ç´ æ™‚é–“æˆ³ (phoneme timestamps)

    // ç°¡åŒ–ç‰ˆ: ä½¿ç”¨ Whisper çš„ word timestamps
    const phonemes: Phoneme[] = [];

    for (const segment of segments) {
      const chars = segment.text.split('');
      const duration = (segment.end - segment.start) / chars.length;

      for (let i = 0; i < chars.length; i++) {
        const pinyin = await this.getPinyin(chars[i]);
        phonemes.push({
          phoneme: pinyin,
          start: segment.start + i * duration,
          end: segment.start + (i + 1) * duration,
        });
      }
    }

    return phonemes;
  }

  /**
   * æ¯”è¼ƒéŸ³ç´ ç›¸ä¼¼åº¦ (DTW - Dynamic Time Warping)
   */
  private comparePhonemes(expected: Phoneme[], actual: Phoneme[]): number {
    // ä½¿ç”¨ DTW å°é½ŠéŸ³ç´ åºåˆ— (è™•ç†èªé€Ÿä¸åŒ)
    // è¨ˆç®—éŸ³ç´ åŒ¹é…ç‡

    let matches = 0;
    const minLength = Math.min(expected.length, actual.length);

    for (let i = 0; i < minLength; i++) {
      if (expected[i].phoneme === actual[i].phoneme) {
        matches++;
      }
    }

    return matches / Math.max(expected.length, actual.length);
  }

  /**
   * å–å¾—å­—çš„æ³¨éŸ³/æ‹¼éŸ³
   */
  private async getPinyin(char: string): Promise<string> {
    // æŸ¥è©¢è³‡æ–™åº« vocabulary è¡¨ (é è¼‰çš„ç”Ÿå­—è¡¨æœ‰æ³¨éŸ³)
    const vocab = await this.prisma.vocabulary.findFirst({
      where: { character: char },
    });

    return vocab?.pinyin || this.fallbackPinyin(char);
  }

  /**
   * Fallback: ä½¿ç”¨å¤–éƒ¨ API (å¦‚ pinyin å¥—ä»¶)
   */
  private fallbackPinyin(char: string): string {
    const pinyin = require('pinyin');
    return pinyin(char, { style: pinyin.STYLE_NORMAL })[0][0];
  }
}
```

---

## 4ï¸âƒ£ æµæš¢åº¦è©•åˆ†

### 4.1 è©•åˆ†æŒ‡æ¨™

```typescript
// src/services/FluencyService.ts
import { Injectable } from '@nestjs/common';

@Injectable()
export class FluencyService {
  /**
   * è¨ˆç®—æµæš¢åº¦åˆ†æ•¸ (0-100)
   */
  calculateFluency(
    segments: WhisperSegment[],
    totalDuration: number,
    expectedText: string
  ): FluencyResult {
    // 1. è¨ˆç®—èªé€Ÿ (å­—/åˆ†é˜)
    const charactersPerMinute = this.calculateSpeechRate(segments, totalDuration);

    // 2. è¨ˆç®—åœé “æ¬¡æ•¸
    const pauses = this.detectPauses(segments);

    // 3. è¨ˆç®—èªé€Ÿåˆ†æ•¸ (åƒè€ƒæ¨™æº–: å°å­¸ç”Ÿæœ—è®€ 80-120 å­—/åˆ†é˜)
    const speechRateScore = this.scoreSpeechRate(charactersPerMinute, 80, 120);

    // 4. è¨ˆç®—åœé “åˆ†æ•¸ (éå¤šåœé “æ‰£åˆ†)
    const pauseScore = this.scorePauses(pauses, expectedText.length);

    // 5. ç¶œåˆæµæš¢åº¦åˆ†æ•¸
    const fluency = speechRateScore * 0.6 + pauseScore * 0.4;

    return {
      fluency,
      charactersPerMinute,
      pauseCount: pauses.length,
      averagePauseDuration: pauses.reduce((sum, p) => sum + p.duration, 0) / pauses.length,
    };
  }

  /**
   * è¨ˆç®—èªé€Ÿ (å­—/åˆ†é˜)
   */
  private calculateSpeechRate(segments: WhisperSegment[], totalDuration: number): number {
    const totalCharacters = segments.reduce((sum, seg) => sum + seg.text.length, 0);
    return (totalCharacters / totalDuration) * 60;
  }

  /**
   * åµæ¸¬åœé “ (segment ä¹‹é–“çš„ç©ºéš™)
   */
  private detectPauses(segments: WhisperSegment[]): Pause[] {
    const pauses: Pause[] = [];

    for (let i = 0; i < segments.length - 1; i++) {
      const gap = segments[i + 1].start - segments[i].end;

      // åœé “ > 0.5 ç§’æ‰ç®—
      if (gap > 0.5) {
        pauses.push({
          start: segments[i].end,
          end: segments[i + 1].start,
          duration: gap,
        });
      }
    }

    return pauses;
  }

  /**
   * è©•åˆ†èªé€Ÿ (æ¨™æº–ç¯„åœ: minRate - maxRate)
   */
  private scoreSpeechRate(rate: number, minRate: number, maxRate: number): number {
    if (rate < minRate) {
      // å¤ªæ…¢
      return Math.max(0, (rate / minRate) * 100);
    } else if (rate > maxRate) {
      // å¤ªå¿«
      return Math.max(0, (maxRate / rate) * 100);
    } else {
      // åœ¨æ¨™æº–ç¯„åœå…§
      return 100;
    }
  }

  /**
   * è©•åˆ†åœé “ (éå¤šåœé “æ‰£åˆ†)
   */
  private scorePauses(pauses: Pause[], textLength: number): number {
    // åƒè€ƒæ¨™æº–: æ¯ 20 å€‹å­—å¯ä»¥æœ‰ 1 æ¬¡åœé “
    const expectedPauses = textLength / 20;
    const excessPauses = Math.max(0, pauses.length - expectedPauses);

    // æ¯å¤š 1 æ¬¡åœé “æ‰£ 5 åˆ†
    return Math.max(0, 100 - excessPauses * 5);
  }
}
```

---

## 5ï¸âƒ£ ç¶œåˆè©•åˆ†å¼•æ“

```typescript
// src/services/ScoringEngine.ts
import { Injectable, Logger } from '@nestjs/common';
import { WhisperService } from './WhisperService';
import { TextComparisonService } from './TextComparisonService';
import { PronunciationService } from './PronunciationService';
import { FluencyService } from './FluencyService';
import { PrismaService } from '../prisma/prisma.service';

@Injectable()
export class ScoringEngine {
  private readonly logger = new Logger(ScoringEngine.name);

  constructor(
    private whisper: WhisperService,
    private textComparison: TextComparisonService,
    private pronunciation: PronunciationService,
    private fluency: FluencyService,
    private prisma: PrismaService,
  ) {}

  /**
   * ä¸»è¦è©•åˆ†æµç¨‹
   */
  async scoreSubmission(submissionId: string): Promise<ScoringResult> {
    this.logger.log(`Scoring submission: ${submissionId}`);

    // 1. å–å¾—æäº¤è¨˜éŒ„
    const submission = await this.prisma.submission.findUnique({
      where: { submission_id: submissionId },
      include: {
        assignment: {
          include: {
            node: {
              include: {
                learning_materials: true, // å–å¾—èª²æ–‡å…§å®¹
              },
            },
          },
        },
        submission_files: true,
      },
    });

    const audioFile = submission.submission_files.find(f => f.file_type === 'audio');
    if (!audioFile) {
      throw new Error('No audio file found');
    }

    // 2. ä¸‹è¼‰éŸ³æª” (å¾ S3)
    const localAudioPath = await this.downloadFromS3(audioFile.file_url);

    // 3. STT: éŸ³æª” â†’ æ–‡å­—
    const whisperResult = await this.whisper.transcribe(localAudioPath);
    this.logger.log(`Transcribed text: ${whisperResult.text}`);

    // 4. å–å¾—é æœŸæ–‡å­— (èª²æ–‡å…§å®¹)
    const expectedText = submission.assignment.node.learning_materials
      .find(m => m.material_type === 'text')?.content || '';

    // 5. è¨ˆç®—æº–ç¢ºæ€§
    const accuracyResult = this.textComparison.calculateAccuracy(expectedText, whisperResult.text);

    // 6. è¨ˆç®—ç™¼éŸ³æº–ç¢ºåº¦
    const pronunciationScore = await this.pronunciation.calculatePronunciationScore(
      localAudioPath,
      expectedText,
      whisperResult.segments
    );

    // 7. è¨ˆç®—æµæš¢åº¦
    const fluencyResult = this.fluency.calculateFluency(
      whisperResult.segments,
      audioFile.duration_seconds,
      expectedText
    );

    // 8. ç¶œåˆè©•åˆ†
    const finalScore =
      pronunciationScore * 0.4 +
      fluencyResult.fluency * 0.3 +
      accuracyResult.accuracy * 0.3;

    // 9. å„²å­˜è©•åˆ†è¨˜éŒ„
    await this.saveScore(submissionId, {
      score_type: 'ai_auto',
      score_value: finalScore,
      criteria: {
        pronunciation: pronunciationScore,
        fluency: fluencyResult.fluency,
        accuracy: accuracyResult.accuracy,
        details: {
          recognized_text: whisperResult.text,
          errors: accuracyResult.errors,
          speech_rate: fluencyResult.charactersPerMinute,
          pause_count: fluencyResult.pauseCount,
        },
      },
      feedback: this.generateFeedback({
        pronunciationScore,
        fluencyResult,
        accuracyResult,
      }),
    });

    // 10. æ›´æ–° submission ç‹€æ…‹
    await this.prisma.submission.update({
      where: { submission_id: submissionId },
      data: {
        status: 'graded',
        final_score: finalScore,
        graded_at: new Date(),
      },
    });

    this.logger.log(`Scoring completed: ${finalScore}`);

    return {
      finalScore,
      pronunciationScore,
      fluencyScore: fluencyResult.fluency,
      accuracyScore: accuracyResult.accuracy,
    };
  }

  /**
   * ç”Ÿæˆ AI å›é¥‹
   */
  private generateFeedback(result: any): string {
    const feedback: string[] = [];

    // ç™¼éŸ³å›é¥‹
    if (result.pronunciationScore >= 90) {
      feedback.push('âœ… ç™¼éŸ³éå¸¸æ¨™æº–!');
    } else if (result.pronunciationScore >= 70) {
      feedback.push('âš ï¸ ç™¼éŸ³é‚„ä¸éŒ¯,ä½†æœ‰äº›å­—éœ€è¦å†ç·´ç¿’');
    } else {
      feedback.push('âŒ ç™¼éŸ³éœ€è¦å¤šåŠ ç·´ç¿’,å»ºè­°è½è€å¸«ç¤ºç¯„');
    }

    // æµæš¢åº¦å›é¥‹
    if (result.fluencyResult.fluency >= 90) {
      feedback.push('âœ… æœ—è®€éå¸¸æµæš¢!');
    } else if (result.fluencyResult.pauseCount > 5) {
      feedback.push(`âš ï¸ åœé “æ¬¡æ•¸è¼ƒå¤š (${result.fluencyResult.pauseCount} æ¬¡),å»ºè­°å¤šç·´ç¿’å¹¾æ¬¡`);
    }

    // æº–ç¢ºæ€§å›é¥‹
    if (result.accuracyResult.errors.length > 0) {
      const errorChars = result.accuracyResult.errors.map(e => e.expected).join('ã€');
      feedback.push(`âŒ ä»¥ä¸‹å­—è©éœ€è¦æ³¨æ„: ${errorChars}`);
    } else {
      feedback.push('âœ… å®Œå…¨æ­£ç¢º!');
    }

    return feedback.join('\n');
  }

  /**
   * å„²å­˜è©•åˆ†è¨˜éŒ„
   */
  private async saveScore(submissionId: string, data: any) {
    await this.prisma.score.create({
      data: {
        submission_id: submissionId,
        ...data,
      },
    });
  }
}
```

---

## 6ï¸âƒ£ éåŒæ­¥è™•ç† (Queue)

```typescript
// src/queues/ScoringQueue.ts
import { Injectable } from '@nestjs/common';
import { Queue } from 'bull';
import { InjectQueue } from '@nestjs/bull';

@Injectable()
export class ScoringQueue {
  constructor(
    @InjectQueue('scoring') private scoringQueue: Queue,
  ) {}

  /**
   * åŠ å…¥è©•åˆ†ä»»å‹™åˆ° Queue
   */
  async addScoringJob(submissionId: string) {
    await this.scoringQueue.add('score-submission', {
      submissionId,
    }, {
      attempts: 3, // é‡è©¦ 3 æ¬¡
      backoff: {
        type: 'exponential',
        delay: 2000,
      },
    });
  }
}

// src/queues/ScoringProcessor.ts
import { Process, Processor } from '@nestjs/bull';
import { Job } from 'bull';
import { ScoringEngine } from '../services/ScoringEngine';

@Processor('scoring')
export class ScoringProcessor {
  constructor(private scoringEngine: ScoringEngine) {}

  @Process('score-submission')
  async handleScoring(job: Job) {
    const { submissionId } = job.data;
    await this.scoringEngine.scoreSubmission(submissionId);
  }
}
```

---

## 7ï¸âƒ£ éƒ¨ç½²: Whisper GPU åŠ é€Ÿ

### 7.1 Docker é…ç½®

```dockerfile
# Dockerfile.whisper
FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04

# å®‰è£ Python + Whisper
RUN apt-get update && apt-get install -y python3 python3-pip ffmpeg
RUN pip3 install openai-whisper

# ä¸‹è¼‰ Whisper Medium æ¨¡å‹
RUN whisper --model medium --download-root /models dummy.wav || true

EXPOSE 8000
CMD ["python3", "whisper_server.py"]
```

### 7.2 Whisper HTTP Server

```python
# whisper_server.py
from flask import Flask, request, jsonify
import whisper
import os

app = Flask(__name__)
model = whisper.load_model("medium")

@app.route('/transcribe', methods=['POST'])
def transcribe():
    # æ¥æ”¶éŸ³æª”
    audio_file = request.files['audio']
    audio_path = f"/tmp/{audio_file.filename}"
    audio_file.save(audio_path)

    # STT
    result = model.transcribe(audio_path, language='zh')

    # åˆªé™¤æš«å­˜æª”
    os.remove(audio_path)

    return jsonify(result)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8000)
```

### 7.3 Kubernetes Deployment (GPU Node)

```yaml
# k8s/whisper-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: whisper-service
spec:
  replicas: 2
  selector:
    matchLabels:
      app: whisper
  template:
    metadata:
      labels:
        app: whisper
    spec:
      nodeSelector:
        gpu: nvidia # GPU ç¯€é»
      containers:
      - name: whisper
        image: literacy-platform/whisper:latest
        resources:
          limits:
            nvidia.com/gpu: 1 # 1 å¼µ GPU
        ports:
        - containerPort: 8000
```

---

## 8ï¸âƒ£ æˆæœ¬åˆ†æ

### 8.1 Self-Hosted Whisper æˆæœ¬

| é …ç›® | è¦æ ¼ | æˆæœ¬ (æœˆ) |
|------|------|----------|
| **GPU ä¼ºæœå™¨** | NVIDIA T4 (GCP) | $300 |
| **å„²å­˜** | 100 GB SSD | $20 |
| **ç¶²è·¯** | 1 TB å‚³è¼¸ | $10 |
| **ç¸½è¨ˆ** | - | **$330/æœˆ** |

**è™•ç†é‡**: 1 å¼µ T4 GPU å¯è™•ç† ~500 å€‹éŸ³æª”/å°æ™‚

**æ¯å€‹éŸ³æª”æˆæœ¬**: $330 / (500 Ã— 30 Ã— 8) = **$0.0028/æ¬¡** (ç›¸æ¯” Azure $1/1000 æ¬¡ = $0.001/æ¬¡)

### 8.2 èˆ‡ SaaS å°æ¯”

| æ–¹æ¡ˆ | æˆæœ¬ (150,000 æ¬¡/å­¸æœŸ) |
|------|----------------------|
| **Azure Speech API** | $150 |
| **Self-Hosted Whisper** | $330 (å›ºå®šæˆæœ¬) |

**çµè«–**:
- ç”¨é‡ < 33,000 æ¬¡/æœˆ â†’ Azure è¼ƒä¾¿å®œ
- ç”¨é‡ > 33,000 æ¬¡/æœˆ â†’ Self-Hosted è¼ƒä¾¿å®œ

æˆ‘å€‘é ä¼° 150,000 æ¬¡/å­¸æœŸ = 25,000 æ¬¡/æœˆ â†’ **ä½¿ç”¨ Azure æ›´åˆ’ç®—** ($150 vs $330)

---

## 9ï¸âƒ£ æ¸¬è©¦ç­–ç•¥

### 9.1 æº–ç¢ºç‡æ¸¬è©¦

```typescript
// src/services/__tests__/ScoringEngine.test.ts
import { ScoringEngine } from '../ScoringEngine';

describe('ScoringEngine', () => {
  it('should score perfect pronunciation as 100', async () => {
    const result = await scoringEngine.scoreSubmission('test-submission-1');
    expect(result.finalScore).toBeGreaterThan(95);
  });

  it('should detect mispronunciation', async () => {
    // éŸ³æª”: æ•…æ„å”¸éŒ¯æŸäº›å­—
    const result = await scoringEngine.scoreSubmission('test-submission-error');
    expect(result.pronunciationScore).toBeLessThan(70);
  });

  it('should detect pauses correctly', async () => {
    // éŸ³æª”: æ•…æ„åœé “å¾ˆå¤šæ¬¡
    const result = await scoringEngine.scoreSubmission('test-submission-pauses');
    expect(result.fluencyScore).toBeLessThan(60);
  });
});
```

---

## ğŸ”Ÿ ç›£æ§èˆ‡å„ªåŒ–

### 10.1 Prometheus Metrics

```typescript
// src/metrics/ScoringMetrics.ts
import { Histogram, Counter } from 'prom-client';

export const scoringDuration = new Histogram({
  name: 'scoring_duration_seconds',
  help: 'Time taken to score a submission',
  buckets: [5, 10, 30, 60, 120],
});

export const scoringSuccess = new Counter({
  name: 'scoring_success_total',
  help: 'Total successful scorings',
});

export const scoringFailure = new Counter({
  name: 'scoring_failure_total',
  help: 'Total failed scorings',
  labelNames: ['error_type'],
});
```

---

## ğŸ¯ ç¸½çµ

### è©•åˆ†å¼•æ“èƒ½åŠ›ç¢ºèª

| èƒ½åŠ› | å¯¦ç¾æ–¹å¼ | æº–ç¢ºç‡ |
|------|---------|--------|
| **STT** | Whisper Medium | >95% (ä¸­æ–‡) |
| **æº–ç¢ºæ€§** | Levenshtein Distance | >90% |
| **ç™¼éŸ³** | éŸ³ç´ æ¯”å° | ~85% |
| **æµæš¢åº¦** | åœé “ + èªé€Ÿ | ~90% |

### æŠ€è¡“é¸å‹

| æŠ€è¡“ | é¸æ“‡ | åŸå›  |
|------|------|------|
| **STT å¼•æ“** | Azure Speech API | æˆæœ¬æœ€å„ª ($150/æœˆ) |
| **éŸ³ç´ åˆ†æ** | è‡ªè¨‚æ¼”ç®—æ³• | é¿å…ä¾è³´ä»˜è²» API |
| **éåŒæ­¥è™•ç†** | Bull Queue | é«˜ä¸¦ç™¼è™•ç† |

### é–‹ç™¼æ™‚ç¨‹

| éšæ®µ | æ™‚é–“ | ç”¢å‡º |
|------|------|------|
| 1. Whisper æ•´åˆ | 2 å¤© | WhisperService.ts |
| 2. æ–‡å­—æ¯”å° | 1 å¤© | TextComparisonService.ts |
| 3. ç™¼éŸ³åˆ†æ | 3 å¤© | PronunciationService.ts |
| 4. æµæš¢åº¦åˆ†æ | 2 å¤© | FluencyService.ts |
| 5. ç¶œåˆå¼•æ“ | 2 å¤© | ScoringEngine.ts |
| 6. Queue æ•´åˆ | 1 å¤© | ScoringQueue.ts |
| 7. æ¸¬è©¦èˆ‡èª¿å„ª | 3 å¤© | æ¸¬è©¦ + æº–ç¢ºç‡å„ªåŒ– |
| **ç¸½è¨ˆ** | **14 å¤©** | å®Œæ•´ AI è©•åˆ†å¼•æ“ |

---

## ğŸ“ å¾ŒçºŒæ–‡ä»¶

âœ… **å®Œæˆ**: è³‡æ–™åº« Schema è¨­è¨ˆ
âœ… **å®Œæˆ**: GitHub åŒæ­¥æœå‹™è¨­è¨ˆ
âœ… **å®Œæˆ**: Google Classroom æ•´åˆè¨­è¨ˆ
âœ… **å®Œæˆ**: AI è©•åˆ†å¼•æ“è¨­è¨ˆ
â­ï¸ **ä¸‹ä¸€æ­¥**: å‰ç«¯è¨­è¨ˆ.md (å­¸ç”Ÿç«¯ + æ•™å¸«ç«¯)
